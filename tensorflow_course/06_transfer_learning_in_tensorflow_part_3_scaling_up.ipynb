{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fachiny17/machine_learning/blob/main/tensorflow_course/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transfer learning with tensorflow part 3: scaling up (food vision mini)\n",
        "\n",
        "Our goal is to beat the original Food101 paper with 10% of the training (leveraging the power of deep learning).\n",
        "Our baseline to beat is 50.76% accuracy across 101 classes."
      ],
      "metadata": {
        "id": "iVNwci_erXaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Vy6iBCGL_B-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc6f489-c22f-41d7-8dac-ab9e0e282d3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "jDC_3YJUuH1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f4e00c-2051-4e58-f2c1-c7b0c7c633e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-07 08:55:02--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-11-07 08:55:02 (13.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, walk_through_dir, plot_loss_curves, compare_historys, unzip_data"
      ],
      "metadata": {
        "id": "W7A5fnrp29_P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 101 food classes: working with less data"
      ],
      "metadata": {
        "id": "1_lDX_3d3NLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sldE5Tvn3boN",
        "outputId": "ff56e2fe-b7ee-4d4f-adfa-7cb422bc446e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-07 08:55:14--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.107.207, 74.125.196.207, 173.194.216.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.107.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "         101_food_c   1%[                    ]  26.12M   131MB/s               "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images/classes are there?\n",
        "walk_through_dir(\"101_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "vYlqgoc04FXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup data inputs\n",
        "\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                               label_mode=\"categorical\",\n",
        "                                                                               image_size=IMG_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                shuffle=False) # don't shuffle the test data"
      ],
      "metadata": {
        "id": "zl13C7BF4-5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train a big dog model with transfer learning on 10% of 101 food classes\n",
        "\n",
        "Here are the steps we're going to take:\n",
        "* create a ModelChecpoint callback\n",
        "* create a data augmentation layer to build data augmentation right in the model\n",
        "* build a headless (no top layers) Functional EfficientNetB0 backboned-model (we'll create our own output layer)\n",
        "* compile our model\n",
        "* feature extract for 5 full passes (5 epochs on train dataset and validate on 15% of the test data to save epoch time)"
      ],
      "metadata": {
        "id": "Is9DVMra6_E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create checkpoint callback\n",
        "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint.weights.h5\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         monitor=\"val_accuracy\",\n",
        "                                                         save_best_only=True)"
      ],
      "metadata": {
        "id": "5PfSfjBi_goA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data augmentation layer to incorporate it right into the model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "# Setup data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2),\n",
        "    layers.RandomZoom(0.2)\n",
        "], name = \"data_augmentation\")"
      ],
      "metadata": {
        "id": "bHIG43ovEETj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the base model and freeze its layers (this will extract features)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# setup model architecture with trainable top layers\n",
        "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "x = data_augmentation(inputs) # augments images (only happens during training phase)\n",
        "x = base_model(x, training=False) # put the base model in inference mode so weigts which need to stay frozen, stay frozen\n",
        "x = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n",
        "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "gQpDa34SFGwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of model we've created\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6sYUKFZz1fqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit\n",
        "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
        "                                           epochs=5,\n",
        "                                           validation_data=test_data,\n",
        "                                           validation_steps=int(0.15 * len(test_data)),\n",
        "                                           callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "v1HVOrzB37ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the whole test dataset\n",
        "feature_extraction_results = model.evaluate(test_data)\n",
        "feature_extraction_results"
      ],
      "metadata": {
        "id": "r6XzSmQe28sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_all_classes_10_percent)"
      ],
      "metadata": {
        "id": "kaFVgdo87Pwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "4vG2MNs27rMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all of the layers in the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze every layer except the last 5\n",
        "for layer in base_model.layers[:-5]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "J_A-73XN9GJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompile model with lower learning rate\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # learning_rate reduced by 10x\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "avPWUC-29ON3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What layers in the model are trainable?\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "nRuSIwtM_Xaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which layers are trainable in our base model\n",
        "for layer_number, layer in enumerate(model.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "i8BVNOhg_rTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune for 5 more epochs\n",
        "fine_tune_epochs = 10\n",
        "\n",
        "# Fine-tune our model\n",
        "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
        "                                                     epochs=fine_tune_epochs,\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps = int(0.15 * len(test_data)),\n",
        "                                                     initial_epoch = history_all_classes_10_percent.epoch[-1])"
      ],
      "metadata": {
        "id": "rJJbzNXSAXhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the whole test_data\n",
        "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
        "all_classes_10_percent_fine_tune_results"
      ],
      "metadata": {
        "id": "m2FYTQw_DH8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the histories of feature extraction model with fine-tuning model\n",
        "compare_historys(original_history=history_all_classes_10_percent,\n",
        "                  new_history=history_all_classes_10_percent_fine_tune,\n",
        "                  initial_epochs=5)"
      ],
      "metadata": {
        "id": "ck3EgvKuFVcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading our model\n",
        "To use our model in an external application, we'll need to save it and export it somewhere"
      ],
      "metadata": {
        "id": "kfAQvwQTHmAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our fine-tuning model\n",
        "model.save(\"/content/drive/MyDrive/tensorflow_course/101_food_classes_10_percent_data_model.keras\")"
      ],
      "metadata": {
        "id": "_oecrbqsI4Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an evaluate saved model\n",
        "loaded_model = tf.keras.models.load_model(\"/content/drive/MyDrive/tensorflow_course/101_food_classes_10_percent_data_model.keras\")"
      ],
      "metadata": {
        "id": "HeC5gmmLJY4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model and compare performance to pre-saved model\n",
        "loaded_model_results = loaded_model.evaluate(test_data)\n",
        "loaded_model_results"
      ],
      "metadata": {
        "id": "4FQGfPVZNGsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The results from ourloaded_model (above) should be very similar to the results below\n",
        "all_classes_10_percent_fine_tune_results"
      ],
      "metadata": {
        "id": "Mn3-I2pRYZnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the performance of the big dog model across all different classes\n",
        "Let's make some predictions, visualize them and then later find out which predictions were the \"most\" wrong"
      ],
      "metadata": {
        "id": "MyGRgy3mY2fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# !wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_classes_10_percent_saved_big_dog_model.zip"
      ],
      "metadata": {
        "id": "7pcY581wcdxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data('/content/drive/MyDrive/tensorflow_course/06_101_food_class_10_percent_saved_big_dog_model.zip')"
      ],
      "metadata": {
        "id": "1fm5fO-odIt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "543499c1"
      },
      "source": [
        "!ls -R /content/06_101_food_class_10_percent_saved_big_dog_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "689bc505"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# # Load in saved model using tf.saved_model.load\n",
        "# model = tf.keras.models.load_model('/content/06_101_food_class_10_percent_saved_big_dog_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded Keras Model on test data\n",
        "results_downloaded_model = model.evaluate(test_data)\n",
        "results_downloaded_model"
      ],
      "metadata": {
        "id": "jaULEK3SDV6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions with our trained model"
      ],
      "metadata": {
        "id": "u3w7LlpDFIU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "preds_probs = model.predict(test_data, verbose=1)"
      ],
      "metadata": {
        "id": "elbcFVrDisJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many predictions are there?\n",
        "len(preds_probs)"
      ],
      "metadata": {
        "id": "4Xd6QYgHjOdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the shape of our predictions?\n",
        "preds_probs.shape"
      ],
      "metadata": {
        "id": "CaaanHngjpIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what the first 10 predictions look like\n",
        "preds_probs[:10]"
      ],
      "metadata": {
        "id": "y2pIJKtsjyBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the first prediction probability array look like?\n",
        "preds_probs[0], len(preds_probs[0]), sum(preds_probs[0])"
      ],
      "metadata": {
        "id": "fas5WqfqkJdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model outputs a prediction probability array (with N number of variables, where N is the number of classes) for each sample passed to the predict method"
      ],
      "metadata": {
        "id": "lT0UiBGpkiWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get one prediction probability per class (in our case there's 101 prediction probabilities)\n",
        "print(f\"Number of prediction probabilities for sample 0: {len(preds_probs[0])}\")\n",
        "print(f\"What prediction probability sample 0 looks like: {preds_probs[0]}\")\n",
        "print(f\"The class with the highest predicted probability by the model for sample 0: {preds_probs[0].argmax()}\")"
      ],
      "metadata": {
        "id": "5m5kUYSllXfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.class_names[0]"
      ],
      "metadata": {
        "id": "XFGc2f2BmgOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the pred classes of each label\n",
        "pred_classes = preds_probs.argmax(axis=1)\n",
        "\n",
        "# How do they look?\n",
        "pred_classes[:10]"
      ],
      "metadata": {
        "id": "FsWZhU20m_5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many pred classes do we have?\n",
        "len(pred_classes)"
      ],
      "metadata": {
        "id": "mtZeprlhntwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Now we've got a prediction array of all our model's predictions. to evaluate them, we need to compare them to the labels."
      ],
      "metadata": {
        "id": "zxahxiyUoBLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get our test labels we need to unravel our test_data BatchDataset\n",
        "y_labels = []\n",
        "for images, labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax())\n",
        "y_labels[:10] #look at the first 10"
      ],
      "metadata": {
        "id": "IQqUFnt7rN6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_labels)"
      ],
      "metadata": {
        "id": "jO9YeMeXtGLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate our model's predictions"
      ],
      "metadata": {
        "id": "DjFX5WIctjxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_downloaded_model"
      ],
      "metadata": {
        "id": "jRKBkwT7GIfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try scikit-learn's accuracy score function and see what it comes up with\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sklearn_accuracy = accuracy_score(y_true=y_labels,\n",
        "                                  y_pred=pred_classes)\n",
        "sklearn_accuracy"
      ],
      "metadata": {
        "id": "ERZ7qmQiGOpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does this metric come close to our model's evaluate results\n",
        "import numpy as np\n",
        "np.isclose(results_downloaded_model[1], sklearn_accuracy)"
      ],
      "metadata": {
        "id": "S4DHKMZdGu4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's get visual: making a confusion matrix"
      ],
      "metadata": {
        "id": "r-CxlhOfHUA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import make_confusion_matrix"
      ],
      "metadata": {
        "id": "ckTTbNJtSG4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = test_data.class_names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "id": "ZVcVSPk6So5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to make some changes to our make_confusion_matrix function to ensure the x-labels print vertically\n",
        "\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Changed (plot x-labels vertically) ###\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n"
      ],
      "metadata": {
        "id": "zuqg4dhnVbcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_confusion_matrix(y_true=y_labels,\n",
        "                      y_pred=pred_classes,\n",
        "                      classes=class_names,\n",
        "                      figsize=(100, 100),\n",
        "                      text_size = 20)"
      ],
      "metadata": {
        "id": "DTKD5CNlSxa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's keep the evaluation train going, time for a classification report\n",
        "\n",
        "Scikit-learn has a helpful function for acquiring many different classification metrics per class (e.g. precision, recall and F1) called [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ],
      "metadata": {
        "id": "6LDuZc9gTM45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true=y_labels,\n",
        "                           y_pred=pred_classes))"
      ],
      "metadata": {
        "id": "Pt9VysPDdBtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numbers above give a great class-by-class evaluation of our model's predictions but with so many classes, they're quite hard to understand.\n",
        "\n",
        "How about we create a visualization to get a better understanding?"
      ],
      "metadata": {
        "id": "NWOo2FZ3jV_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary of the classification report\n",
        "classification_report_dict = classification_report(y_true=y_labels,\n",
        "                                                  y_pred=pred_classes,\n",
        "                                                  output_dict=True)\n",
        "classification_report_dict"
      ],
      "metadata": {
        "id": "Bf7Cl8ulknrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot all of our classes F!-scores"
      ],
      "metadata": {
        "id": "XPCkkG4-lbdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty dictionary\n",
        "class_f1_scores = {}\n",
        "# Loop through classification report dictionary items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\":\n",
        "    break\n",
        "  else:\n",
        "    # Add class names and f1-scores to new dictionary\n",
        "    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores"
      ],
      "metadata": {
        "id": "8bW8gN6amHMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn f1-scores into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n",
        "                          \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)"
      ],
      "metadata": {
        "id": "O_kHHOK2r77w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores"
      ],
      "metadata": {
        "id": "RrmGEh-fupea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1_scores\"].values)\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_yticklabels(f1_scores[\"class_names\"])\n",
        "ax.set_xlabel(\"F1-score\")\n",
        "ax.set_title(\"F1-scores for 101 Different Food Classes (predicted by Food Vision mini)\")\n",
        "ax.invert_yaxis(); # reverse the order of our plot"
      ],
      "metadata": {
        "id": "HnIwTh52ur0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUOEi0INy4Rj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}