{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4453605-8453-4c04-9304-28efcec8bb0f",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn (sklearn)\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "What we're going to cover:\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problems\n",
    "3. Fit the models/algorithm for our problems\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280dc561-0cf1-4635-8099-155f7a29c3f6",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce863b40-f9ad-4821-b3e0-580c2cb5d2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d2360-ab63-4078-8512-ad2d12cb6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the data ready\n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575c7ce-a5e9-44c7-920c-b498225c69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x (features matrix)\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29811ab1-be43-46d1-ab15-6bb9fa1b4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d23351-09e6-4377-a683-1cc26f0c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model to the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298a6f6-22c7-455a-a66d-2a20035d8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ceef9-7c24-485a-9aec-10afae5b8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7720a9-5f6c-4ad6-b1ea-f4b427f1c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "# y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3769f3-12c4-4437-8ede-18e3580d096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2b2d9-5b8c-402c-aefe-98d842b1052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a2593-689c-47da-a3b5-79a131a7c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "clf.score(x_train, y_train) # the model has done a 100% i.e 1.0 (the max that can be gotten) on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda9fb2-5ee1-496e-a069-ff8bb792843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test) # the model gets 0.8197 i.e 81.97% predictions correct on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8e749-e314-4903-b23b-4d40e08839ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019823c2-f40d-4598-aab6-cdf8132828a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9af39c-6dca-41d9-92f1-49275e0a2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988d7e9-d48e-4b00-9f22-de5f872a3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Improve a model\n",
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(x_test, y_test) * 100:.2f}%\") # :.2f is a python shortcut to reduce to 2 decimal places\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4936f8-5a5b-4735-92ea-1ed07d46d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac10dd3-427d-44f1-bffa-212c6c51bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\")) # 'wb' means write binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9096c-545b-46a1-9283-426a5af1bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\")) # 'rb' means read binaries\n",
    "loaded_model.score(x_test, y_test) # the score of the most recent train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b74c0-641b-4401-8332-2e19707b203b",
   "metadata": {},
   "source": [
    "## 1. Getting our data ready to be used with machine learning\n",
    "Three main things we have to do:\n",
    "1. Split the data into features and labels (usually `x` and `y`)\n",
    "2. Filling (alsocalled inputting) or disregarding missing values\n",
    "3. Converting non-numerical values to numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ddedc-c278-473f-9fd3-bd273e61d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4844f50-237e-48a6-8a83-c9217598695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b86032-9e88-4f50-b16b-da958cbce1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b0bc7-9e90-4091-8d45-19c7bb0c1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ecfd2-7184-4a83-a7d8-e2ef5d0f78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c41ec-ce77-4785-9f48-73a2fbf6d2e9",
   "metadata": {},
   "source": [
    "## 1.1 Make sure it's all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3008e1-a0d1-45cc-9142-d48c0d5fd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"data/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60889a-4bff-4bb1-8f59-1ebde66b3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20586ee-27ea-4372-9741-a58ebfbb5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x, y\n",
    "x = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into training and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34162e2-18e0-455c-bd60-32c156eec9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor() # create\n",
    "# model.fit(x_train, y_train) # train\n",
    "# model.score(x_test, y_test) # evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14d5be-a4fc-4a0d-9a66-b774ed5569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ee0d6-ca28-492c-b0aa-a993c8af3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c1449-a02f-42dd-80d7-0af65caca95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]], dtype=int)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168953e-39e2-47f7-96bc-4b3c97daef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed_x, y, test_size=0.2)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0aa27b-031d-4ff5-9426-fb340736ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed5f1c-cb20-42f9-ad77-6e46c209a8ab",
   "metadata": {},
   "source": [
    "### 1.2 What if there were missing values?\n",
    "1. Fill them with some value (also known as imputation).\n",
    "2. Remove the samples with missing data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcd6e0-3b45-49a3-8b61-bf7ab4259573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e83d08-7882-47ba-9f6d-acc9d23de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum() # it shows how many missing data are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b77fb0-1d2d-4e9a-9da6-25c62ca1e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27664ac7-f1f7-4e93-a0c8-6ac63cbb9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21887abb-7a6a-4752-b178-02c7de2c3bab",
   "metadata": {},
   "source": [
    "### Option 1: Fill mising data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c72835-18e2-4cb0-9cfc-7362d16d774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf9429-9ed1-4fe7-9a5d-1b2ffbc77317",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db26a7-7237-4f39-8802-4f17c7f641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price value\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1254a-a51e-4a25-8bf9-f32d78089c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09eef2-41b7-4ad7-9020-1591e3849b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01c0e1-b103-4a14-aa62-06ee56f3cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706880f-2552-47a5-beef-28a583ab1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "transformed_x = transformer.fit_transform(car_sales_missing)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4a66d-eb4c-4464-9d75-4a922ac88d2e",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0dc37-70cb-490b-bf6f-ed97c698111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a518ac-3595-4eeb-8c7a-c3f6718fcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cee825-8e61-4997-9e66-ec5b3d791538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no labels\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab3f1a-fde6-44ca-bf8b-32ce39fda2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x and y\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4e3f5-5ed3-47ac-a345-39c77114fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with Scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill the categorical values with 'missing' and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer= SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define Columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Transform = imputer.fit_transform(x)\n",
    "filled_x = imputer.fit_transform(x)\n",
    "filled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe40c5-6fa0-454c-b4fc-01a6786c892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_x, columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8bca5-8834-4480-b767-d4e9c7e8374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdab414-6150-49f4-89bf-289374d5214e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "transformed_x = transformer.fit_transform(car_sales_filled)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044ca86-ea60-460a-bc92-783215ac598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit the model\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed_x, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193f76e-2e23-4f2b-bd33-dd4a04998bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c15fb4-5bbd-4e3e-8fb3-5ac1d8132b31",
   "metadata": {},
   "source": [
    "`Imputation` is the process of filling-in the missing values. \n",
    "`Feature Engineering or Encoding` is the the process of turning non-numerical values into numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b7b07-5472-4a70-8e4e-2b1d9629139c",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for our problem\n",
    "Scikit-Learn uses estimator as another term for machine learning model or algorithm\n",
    "\n",
    "* Classification - predicting whether a sample is one thing or another.\n",
    "* Regression - predicting a number\n",
    "\n",
    "Step 1: Check the Scikit-Learn machine learning map, https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a87a8-3209-471e-a628-7467c87ca9e2",
   "metadata": {},
   "source": [
    "### 2.1 Picking a machine learning model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50734567-af45-4c86-b2b3-3e234bcfee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import California housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e3e51-3a50-4529-a3df-149e3d5e1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = pd.Series(housing[\"target\"])\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e34767-e942-45b9-a41c-9983c193b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples?\n",
    "len(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574265c1-97b4-4079-8a76-f6899ea45800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the Ridge Regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Ridge model\n",
    "model = Ridge()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Check the score of the Ridge model on test data\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84464230-54e1-4696-a251-a6032385c173",
   "metadata": {},
   "source": [
    "How do we improve this score?\n",
    "\n",
    "What if Ridge wasn't working?\n",
    "\n",
    "Let's refer back to the map... https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cfdaf-9cfb-4ce0-97d3-5576610b8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instatiate Random Forest Regressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Regressor\n",
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ff1d9-c6d9-4768-89a4-b04610625b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Ridge model again\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411ab43-2e41-4f8f-ac5a-db25263f281d",
   "metadata": {},
   "source": [
    "### 2.2 Choosing an estimator for a classification problem\n",
    "Let's go to the map: https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4b8a6-3ee6-403c-8330-2194c2d282e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d67c5-cfa8-4367-8e42-21fed21048aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9446f-58ca-4da1-a684-7c80c46c1f2b",
   "metadata": {},
   "source": [
    "Consulting the `map` and it says to try `LinearSVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bde6e8-32a9-423a-b522-9d960fd4bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "svc = LinearSVC()\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "svc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1478b0-b617-4d56-9ce6-50e00180f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00228882-ed1d-430b-b2b8-8f15a234443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RansomForestCLassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf8a0a-a8c9-4397-af28-01bf0642862b",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "* If you have structured data (tables, DataFrames), use ensemble method such as RandomForest because it will perform well if there are patterns.\n",
    "* If you have unstructured data(images, audio), use deep learning or transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4349e4-c1a1-4c45-bdcc-cfcf18e74a73",
   "metadata": {},
   "source": [
    "## 3. Fit the model/algorithm on our data and use it to make predictions\n",
    "\n",
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for:\n",
    "* `x` = features, features variables, data\n",
    "* `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c89b64-2024-4107-8246-06a4527b2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier (use the patterns the model has learned)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36b900-bbc9-45fe-996c-49f68286450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c89390-2759-442e-adbb-3aab497c26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bc031-9131-40f9-9fe4-9d244412a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a6bec-dd62-46da-8e88-0395ba51f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predictions\n",
    "# clf. predict(np.array([1, 3, 2, 3, 4, 5])) # this doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbf47c-fccf-4529-a4a7-060bf4a1c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5176fb7-9cef-4e69-adbf-5d3f12ee005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cbc91-6b0a-4914-8ec4-d7a3f7225d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68644d7b-c16b-476e-ac9f-92a652d11768",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d119c-c8ed-419e-b652-d4e2df4d64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(x_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf6146-0350-402f-8707-1b7c19f12f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec666add-1c6a-44af-b2d3-61bcab34bea0",
   "metadata": {},
   "source": [
    "Make predictions with `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7fc4a-09f7-4050-b47b-29d44fd06a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic t_prba() returns probabilities of a classification label\n",
    "clf.predict_proba(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2e63a-daa2-4cc0-b1ff-77b91ff6cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict() on the same data\n",
    "clf.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ee8c6-cb93-421a-8f10-f14caaeaa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2effd06-8ca1-42b4-8bff-6f08ecc09550",
   "metadata": {},
   "source": [
    "`predict()` can also beused for regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce70e9b-7971-4f64-bfa0-1fed85d51c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61285558-b31e-4415-922e-c9995d1791e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit model\n",
    "model = RandomForestRegressor().fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c03b9-2118-4dec-913c-ad6109f89264",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a075e67-8b2e-4f78-8ee2-e4a4d3dd19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ef0c2-712a-48ba-a5b5-25ae6bf6b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc5945-78a4-4035-9186-080bcd1b1b51",
   "metadata": {},
   "source": [
    "## 4. Evaluating a machine learning model\n",
    "Three ways to evaluate Scikit-Learn models/estimators:\n",
    "1. Estimator `score` method\n",
    "2. The `scoring` parameter\n",
    "3. Problem-specific metric functions.\n",
    "\n",
    "### 4.1 Evaluating a model with the `score method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc5398-488a-4e60-a460-e37bced80fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d033af-ff9e-429a-bc23-175a87cd3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891a57f-0514-4793-b8be-af21bbe3f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c270866-91e6-484a-9a4a-4c2d315bf8f5",
   "metadata": {},
   "source": [
    "Let's do the same but for regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05161108-7637-4d8c-bb48-14e25409b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit model\n",
    "model = RandomForestRegressor().fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d0d79-168e-470c-beba-bb65ff237632",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c9510-f8ac-4a0f-b9fe-067fb30242c2",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating a model using the `scoring` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461156cd-5d3c-4f60-91ac-67486b69af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f23b39-dcfb-429a-a9b2-d9462fd702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124287d3-b69f-42a6-840d-4c35ea85a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(x_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, x, y, cv=5))\n",
    "\n",
    "# Compare the two\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61325392-69b2-4f8b-841d-84df539e16fb",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b302dfe-5ea2-42e7-9745-722894ef85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d13d7-6d10-44e0-af90-4647e3061e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7be38d-7439-4bf6-8127-d3b7121d31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca491c27-fe59-429f-b3b2-05422610103a",
   "metadata": {},
   "source": [
    "**Area under the receiver operating characteristic curve (AUC/ROC)**\n",
    "* Area under curve (AUC)\n",
    "* ROC curve\n",
    "  \n",
    "ROC curves are a comparison of a model's true positive rate (tpr) versus a models false positive rate (fpr)\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854bbd8-d6f8-41b9-a9ef-f1d22cc2e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x_train, x_test,... etc.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd099a-4942-41e8-aa76-499e7406fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions with probability\n",
    "y_probs = clf.predict_proba(x_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff1038-1682-4734-a5c7-aef4ea35c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:, 1] # getting the 1s using slicing\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09128c1-a459-4c31-844d-74e1a80cdc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresolds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# Check the false positive rates\n",
    "fpr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10c527-b43a-46c4-a59a-ef19c39ef52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0,1], [0,1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794918d3-45a1-436c-937f-4e055afa9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039938b-ee83-4deb-94dc-cab20934a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727357c4-5e25-44d0-958b-19d5c60c4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb4935-0361-4804-8e6f-33ff16802779",
   "metadata": {},
   "source": [
    "**Confusin Matrix**\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict.\n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e55b8-0850-4d8d-8f39-837fee1a5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(x_test)\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c354815-6d15-492a-8890-0e70bfc96b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(y_test,\n",
    "           y_preds,\n",
    "           rownames=[\"Actual Labels\"],\n",
    "           colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d00140-f058-42b8-8950-dae1d53ff9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc2668-d0bf-4dea-9a90-b1c13f5e2528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc7950-e276-4213-a55a-01996f22e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_con_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                    annot=True, # Annotate the boxes with conf_mat info\n",
    "                    cbar=False)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\");\n",
    "\n",
    "plot_con_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf5951-f901-4630-a9d0-ec8589d6aa32",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cdf2a-9d5f-49a7-9123-0a4a16cc284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1841b-d9e5-4274-a944-ae47c2d561ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2e8cf-5c7a-424b-afac-a3a26ed5f65b",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression and model evaluation metrics\n",
    "1. R^2 (pronounced r-squared) or coefficient of determination.\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared eror (MSE)\n",
    "\n",
    "**R^2**\n",
    "\n",
    "What R-squared does: Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfect;y predicts a range of numbers its R^2 value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea25d4-a3a1-41f2-8d6f-7df2621ed40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92214ca2-c540-4970-a2cf-06d5cb286362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad9b23-da1a-474c-8e68-e32370334352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd58a70-34f0-46b0-b644-41d2643c6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc2b4d-988e-488d-b100-b64b58d9b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfead4-9ba3-4eef-8c3d-a16f5b8cc88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945eebb7-4022-45ca-a7a8-379668db93cb",
   "metadata": {},
   "source": [
    "**Mean Absolute Error**\n",
    "\n",
    "MAE is the average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe8eaa-ba82-46ca-b52f-c59557b964a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae # the outcome means: the predicted value is + or - of mae away from the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30309a2-668c-4d28-98fa-0ed9088d4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test,\n",
    "                       \"predicted values\": y_preds})\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305199aa-5737-431b-9ad6-e976ab05b403",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7fab3-8e38-4bb7-9b28-c24211333c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec126e75-2fa0-42d0-907f-17e5d58c8d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE by hand\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e81fa-22ee-4246-8359-0a27e871babf",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6e2db-5cba-435b-9dfb-1bb8d6b48fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533ef3d-fb32-4bf1-bcaf-c7a56aea95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, x, y, cv=5, scoring=None)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3940f88-c8f7-4f57-9c3f-3db3e72e6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adcf3d-2ec1-4d29-91e3-06f39bcac41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, x, y, cv=5, scoring=\"accuracy\")\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db2b53-1fab-472c-9ace-2516ab3566ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "cv_precision = cross_val_score(clf, x, y, cv=5, scoring=\"precision\")\n",
    "np.mean(cv_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223de76-5320-4d84-aa0c-d43d65b3074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "cv_recall = cross_val_score(clf, x, y, cv=5, scoring=\"recall\")\n",
    "np.mean(cv_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c30637-bc94-454f-a1db-472369f30035",
   "metadata": {},
   "source": [
    "How about our regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966add78-0be2-401d-b93f-08a6fa0ffc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13245dbe-48c9-4ebd-80ee-325b7ad4c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, x, y, cv=5, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da4bc4-372a-424c-8ace-36ad39ef0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, x, y, cv=5, scoring=\"r2\")\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2f261-8aa2-46fa-8a51-f544ed68e1fb",
   "metadata": {},
   "source": [
    "### 4.3 Using different evaluation metrics as Scikit-Learn functions\n",
    "**Classification evaluation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae5270-8833-4d22-b742-fb188407f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make some predictions\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f1061-177c-42f7-a0c7-8178e874e851",
   "metadata": {},
   "source": [
    "**Regression evaluation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59187a35-3f34-4b0c-9ba0-bf0c3e45e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make some predictions\n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "# Evaluate the regression\n",
    "print(\"Regression metrics on the test set\")\n",
    "print(f\"R^2: {r2_score(y_test, y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91a293-0507-4e27-88fc-1e6c18a69614",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "First predictions = baseline predictions.\n",
    "First model = base model\n",
    "\n",
    "From a data perspective:\n",
    "* Could we collect more data? (generally, the more data, the better)\n",
    "* Could we improve our data?\n",
    "\n",
    "From a model perspective:\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "\n",
    "Parameters vs. Hyperparameters\n",
    "* Parameters = model find patterns in data.\n",
    "* Hyperparameters = settings on a model you can adjust to (potentially) improve its ability to find patterns.\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9afcd3-6e40-4235-a93f-f5ee38ec6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02aafc2-3200-40ce-8e73-8264b1980f57",
   "metadata": {},
   "source": [
    "### 5.1 Tuning Hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets; training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c218a5-2dc9-4546-b2a6-b7f2cd42cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5027b-08e9-4186-8c9f-af8b943b47fa",
   "metadata": {},
   "source": [
    "We're going to try and adjust:\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc0bfa-2d74-4eb4-b323-2ad88f7c9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Perform evaluation comparison on y_true labels vs. y_preds labels on a classification.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                  \"precision\": round(precision, 2),\n",
    "                  \"recall\": round(recall, 2),\n",
    "                  \"f1\": round(f1, 2)}\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdbf42-dec8-4122-94b1-7e4349e623f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into x and y\n",
    "x = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15% of data\n",
    "x_train, y_train = x[:train_split], y[:train_split]\n",
    "x_valid, y_valid = x[train_split:valid_split], y[train_split:valid_split]\n",
    "x_test, y_test = x[valid_split:], y[valid_split:]\n",
    "\n",
    "clf = RandomForestClassifier() # the default value of n_estimators=100\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make baseline predictions\n",
    "y_preds = clf.predict(x_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd5605-9f1c-4a81-8739-454b50917fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators = 10)\n",
    "clf_2.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(x_valid)\n",
    "\n",
    "# Evaluate the second classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b991c-ee64-48c2-95c9-4e2c9e9b514a",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4a53d-e013-46f8-8bb1-1b86d0649d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "       \"max_depth\": [None, 5, 10, 20, 30],\n",
    "       \"max_features\": [\"auto\", \"sqrt\"],\n",
    "       \"min_samples_split\": [2, 4, 6],\n",
    "       \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into x and y\n",
    "x = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                           param_distributions=grid,\n",
    "                           n_iter=10, # number of models to try (the more it is, the better)\n",
    "                           cv=5, \n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412c458-c9f2-4628-9073-d524f0334ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_ # Combination of hyperparameters that got the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f414b-04a5-4a44-8755-07d969a667e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(x_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344d0e4-1975-470f-9fe7-7a3de418c63b",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "It goes through every single combination available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517a62c-7ad5-46bb-b5f4-7985983df214",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1019e-98da-4236-9dea-2065ebfd21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "grid_2 = {\"n_estimators\": [100, 200, 500],\n",
    "       \"max_depth\": [None],\n",
    "       \"max_features\": [\"auto\", \"sqrt\"],\n",
    "       \"min_samples_split\": [6],\n",
    "       \"min_samples_leaf\": [1, 2]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into x and y\n",
    "x = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_yrain, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                     param_grid=grid_2,\n",
    "                     cv=5,\n",
    "                     verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1ba1c-811c-430b-af21-c673c2738315",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25710d1e-2058-435b-94d5-2740f68c4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_clf.predict(x_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a968d6-d9e2-4454-bfae-0208a5c47a75",
   "metadata": {},
   "source": [
    "Let's compare our different models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773949e4-41fc-4e93-8c4b-cbe0f116fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                               \"clf_2\": clf_2_metrics,\n",
    "                               \"random search\": rs_metrics,\n",
    "                               \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25eacf5-ae54-41b4-b6fe-525d93671a09",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained machine learning \n",
    "\n",
    "Two ways to save and load machine learning models:\n",
    "1. With Python's `pickle` module\n",
    "2. With `joblib` module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea042f-a9c5-4c8b-bc31-cc1fe37cb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(gs_clf, open(\"gs_random_forest_model_1_pickle.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cbc14-9d4d-477a-b09e-4f38f0272e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1_pickle.pk1\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d740e-f7d7-4389-bea0-c563f3a3267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some prdictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(x_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba11ef5-36f8-4203-b9e3-c4730ec39807",
   "metadata": {},
   "source": [
    "**Joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c97b50-c517-4cc4-a42a-859a5f984cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to file\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1_joblib.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488252be-b9de-4f56-afe1-666a86495c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1_joblib.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcfdff-3a70-4ec1-8c98-be3a31495bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and avaluate joblib predictions\n",
    "joblib_y_preds = loaded_joblib_model.predict(x_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c508b-66ab-4ae3-a9fd-0c9769ec6b22",
   "metadata": {},
   "source": [
    "## 7. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c115fb3-aa73-46c2-84f1-1544f03f3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf552-181c-4a8f-8f1a-ca1fbd8f7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21971e50-62d8-40dd-b1a8-5f42cd565935",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3616ea-ba11-4361-96ba-5dc8b5b22d9a",
   "metadata": {},
   "source": [
    "Steps we want to do (all in one cell):\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97b475-aafd-49d7-a79d-84ed215ca90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different  features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "    (\"door\", door_transformer, door_feature),\n",
    "    (\"num\", numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "# Creating a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "x = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c98fd9-805f-4fc9-b580-b5ed123afd08",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "1. Categorical features: They are variables that represent discrete, non-numerical categories(e.g., \"red\", \"dog\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb543e-4a66-4b1f-b00a-2f0d6fa0031d",
   "metadata": {},
   "source": [
    "It's also possible to use `GridSearcCV` or `RandomizedSearchCV` with our `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb200c-592f-47db-a6f9-f94698de2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSaerchCV with our regression Pipeline\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46f7b5-85a0-4ed6-9673-07bd9c2b4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b012d3d-5b27-4f73-9a76-cbe63fb76468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
